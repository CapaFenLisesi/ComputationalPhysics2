<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Computational Physics Lectures: How to optimize codes, from vectorization to parallelization">

<title>Computational Physics Lectures: How to optimize codes, from vectorization to parallelization</title>

<!-- Bootstrap style: bootstrap -->
<link href="http://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Content', 2, None, '___sec0'),
              ('Optimization and profiling', 2, None, '___sec1'),
              ('More on optimization', 2, None, '___sec2'),
              ('Optimization and profiling', 2, None, '___sec3'),
              ('Optimization and debugging', 2, None, '___sec4'),
              ('Other hints', 2, None, '___sec5'),
              ('Vectorization and the basic idea behind parallel computing',
               2,
               None,
               '___sec6'),
              ('A rough classification of hardware models',
               2,
               None,
               '___sec7'),
              ('Shared memory and distributed memory', 2, None, '___sec8'),
              ('Different parallel programming paradigms',
               2,
               None,
               '___sec9'),
              ('Different parallel programming paradigms',
               2,
               None,
               '___sec10'),
              ('What is vectorization?', 2, None, '___sec11'),
              ('Number of elements that can acted upon', 2, None, '___sec12'),
              ('Number of elements that can acted upon, examples',
               2,
               None,
               '___sec13'),
              ('Operation counts for scalar operation', 2, None, '___sec14'),
              ('Number of elements that can acted upon, examples',
               2,
               None,
               '___sec15'),
              ('Number of operations when vectorized', 2, None, '___sec16'),
              ('"A simple test case with and without vectorization":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp"',
               2,
               None,
               '___sec17'),
              ('Compiling with and without vectorization',
               2,
               None,
               '___sec18'),
              ('Compiling with and without vectorization using clang',
               2,
               None,
               '___sec19'),
              ('Automatic vectorization and vectorization inhibitors, criteria',
               2,
               None,
               '___sec20'),
              ('Automatic vectorization and vectorization inhibitors, exit criteria',
               2,
               None,
               '___sec21'),
              ('Automatic vectorization and vectorization inhibitors, straight-line code',
               2,
               None,
               '___sec22'),
              ('Automatic vectorization and vectorization inhibitors, nested loops',
               2,
               None,
               '___sec23'),
              ('Automatic vectorization and vectorization inhibitors, function calls',
               2,
               None,
               '___sec24'),
              ('Automatic vectorization and vectorization inhibitors, data dependencies',
               2,
               None,
               '___sec25'),
              ('Automatic vectorization and vectorization inhibitors, more data dependencies',
               2,
               None,
               '___sec26'),
              ('Automatic vectorization and vectorization inhibitors, memory stride',
               2,
               None,
               '___sec27'),
              ('Memory management', 2, None, '___sec28'),
              ('Memory and communication', 2, None, '___sec29'),
              ('Measuring performance', 2, None, '___sec30'),
              ('Problems with measuring time', 2, None, '___sec31'),
              ('Problems with cold start', 2, None, '___sec32'),
              ('Problems with smart compilers', 2, None, '___sec33'),
              ('Problems with interference', 2, None, '___sec34'),
              ('Problems with measuring performance', 2, None, '___sec35'),
              ('Thomas algorithm for tridiagonal linear algebra equations',
               2,
               None,
               '___sec36'),
              ('Thomas algorithm, forward substitution', 2, None, '___sec37'),
              ('Thomas algorithm, backward substitution',
               2,
               None,
               '___sec38'),
              ('Thomas algorithm and counting of operations (floating point and memory)',
               2,
               None,
               '___sec39'),
              ('"Example: Transpose of a matrix":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp"',
               2,
               None,
               '___sec40'),
              ('"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp"',
               2,
               None,
               '___sec41'),
              ('How do we define speedup? Simplest form',
               2,
               None,
               '___sec42'),
              ('How do we define speedup? Correct baseline',
               2,
               None,
               '___sec43'),
              ('Parallel  speedup', 2, None, '___sec44'),
              ('Speedup and memory', 2, None, '___sec45'),
              ('Upper bounds on speedup', 2, None, '___sec46'),
              ("Amdahl's law", 2, None, '___sec47'),
              ('How much is parallelizable', 2, None, '___sec48'),
              ("Today's situation of parallel computing",
               2,
               None,
               '___sec49'),
              ('Overhead present in parallel computing', 2, None, '___sec50'),
              ('Parallelizing a sequential algorithm', 2, None, '___sec51'),
              ('Strategies', 2, None, '___sec52'),
              ('How do I run MPI on a PC/Laptop?', 2, None, '___sec53'),
              ('Can I do it on my own PC/laptop? OpenMP installation',
               2,
               None,
               '___sec54'),
              ('Installing MPI', 2, None, '___sec55'),
              ('Installing MPI and using Qt', 2, None, '___sec56'),
              ('Using "Smaug":"http://comp-phys.net/cluster-info/using-smaug/", the CompPhys computing cluster',
               2,
               None,
               '___sec57'),
              ('What is Message Passing Interface (MPI)?',
               2,
               None,
               '___sec58'),
              ('Going Parallel with MPI', 2, None, '___sec59'),
              ('MPI is a library', 2, None, '___sec60'),
              ('Bindings to MPI routines', 2, None, '___sec61'),
              ('Communicator', 2, None, '___sec62'),
              ('Some of the most  important MPI functions',
               2,
               None,
               '___sec63'),
              ('"The first MPI C/C++ program":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program2.cpp"',
               2,
               None,
               '___sec64'),
              ('The Fortran program', 2, None, '___sec65'),
              ('Note 1', 2, None, '___sec66'),
              ('"Ordered output with MPIBarrier":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program3.cpp"',
               2,
               None,
               '___sec67'),
              ('Note 2', 2, None, '___sec68'),
              ('"Ordered output":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program4.cpp"',
               2,
               None,
               '___sec69'),
              ('Note 3', 2, None, '___sec70'),
              ('Note 4', 2, None, '___sec71'),
              ('"Numerical integration in parallel":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program6.cpp"',
               2,
               None,
               '___sec72'),
              ('Dissection of trapezoidal rule with $MPI\\_reduce$',
               2,
               None,
               '___sec73'),
              ('Dissection of trapezoidal rule', 2, None, '___sec74'),
              ('Integrating with _MPI_', 2, None, '___sec75'),
              ('How do I use $MPI\\_reduce$?', 2, None, '___sec76'),
              ('More on $MPI\\_Reduce$', 2, None, '___sec77'),
              ('Dissection of trapezoidal rule', 2, None, '___sec78'),
              ('Dissection of trapezoidal rule', 2, None, '___sec79'),
              ('"The quantum dot program for two electrons":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/ParallelizationMPI/MPIvmcqdot.cpp"',
               2,
               None,
               '___sec80'),
              ('What is OpenMP', 2, None, '___sec81'),
              ('Getting started, things to remember', 2, None, '___sec82'),
              ('General code structure', 2, None, '___sec83'),
              ('Parallel region', 2, None, '___sec84'),
              ('Hello world, not again, please!', 2, None, '___sec85'),
              ('Important OpenMP library routines', 2, None, '___sec86'),
              ('Parallel for loop', 2, None, '___sec87'),
              ('Example code', 2, None, '___sec88'),
              ('More on Parallel for loop', 2, None, '___sec89'),
              ('Inner product', 2, None, '___sec90'),
              ('Different threads do different tasks', 2, None, '___sec91'),
              ('Single execution', 2, None, '___sec92'),
              ('Coordination and synchronization', 2, None, '___sec93'),
              ('Data scope', 2, None, '___sec94'),
              ('Some remarks', 2, None, '___sec95'),
              ('Parallelizing nested for-loops', 2, None, '___sec96'),
              ('Nested parallelism', 2, None, '___sec97'),
              ('Parallel tasks', 2, None, '___sec98'),
              ('Common mistakes', 2, None, '___sec99'),
              ('Matrix-matrix multiplication', 2, None, '___sec100'),
              ('Matrix-matrix multiplication', 2, None, '___sec101'),
              ('Matrix-matrix multiplication', 2, None, '___sec102'),
              ('Matrix-matrix multiplication', 2, None, '___sec103')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="para-bs.html">Computational Physics Lectures: How to optimize codes, from vectorization to parallelization</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._para-bs001.html#___sec0" style="font-size: 80%;">Content</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs002.html#___sec1" style="font-size: 80%;">Optimization and profiling</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs003.html#___sec2" style="font-size: 80%;">More on optimization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs004.html#___sec3" style="font-size: 80%;">Optimization and profiling</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs005.html#___sec4" style="font-size: 80%;">Optimization and debugging</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs006.html#___sec5" style="font-size: 80%;">Other hints</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs007.html#___sec6" style="font-size: 80%;">Vectorization and the basic idea behind parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs008.html#___sec7" style="font-size: 80%;">A rough classification of hardware models</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs009.html#___sec8" style="font-size: 80%;">Shared memory and distributed memory</a></li>
     <!-- navigation toc: --> <li><a href="#___sec9" style="font-size: 80%;">Different parallel programming paradigms</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs011.html#___sec10" style="font-size: 80%;">Different parallel programming paradigms</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs012.html#___sec11" style="font-size: 80%;">What is vectorization?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs013.html#___sec12" style="font-size: 80%;">Number of elements that can acted upon</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs014.html#___sec13" style="font-size: 80%;">Number of elements that can acted upon, examples</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs015.html#___sec14" style="font-size: 80%;">Operation counts for scalar operation</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs016.html#___sec15" style="font-size: 80%;">Number of elements that can acted upon, examples</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs017.html#___sec16" style="font-size: 80%;">Number of operations when vectorized</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs018.html#___sec17" style="font-size: 80%;">"A simple test case with and without vectorization":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs019.html#___sec18" style="font-size: 80%;">Compiling with and without vectorization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs020.html#___sec19" style="font-size: 80%;">Compiling with and without vectorization using clang</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs021.html#___sec20" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, criteria</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs022.html#___sec21" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, exit criteria</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs023.html#___sec22" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, straight-line code</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs024.html#___sec23" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, nested loops</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs025.html#___sec24" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, function calls</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs026.html#___sec25" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, data dependencies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs027.html#___sec26" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, more data dependencies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs028.html#___sec27" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, memory stride</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs029.html#___sec28" style="font-size: 80%;">Memory management</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs030.html#___sec29" style="font-size: 80%;">Memory and communication</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs031.html#___sec30" style="font-size: 80%;">Measuring performance</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs032.html#___sec31" style="font-size: 80%;">Problems with measuring time</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs033.html#___sec32" style="font-size: 80%;">Problems with cold start</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs034.html#___sec33" style="font-size: 80%;">Problems with smart compilers</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs035.html#___sec34" style="font-size: 80%;">Problems with interference</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs036.html#___sec35" style="font-size: 80%;">Problems with measuring performance</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs037.html#___sec36" style="font-size: 80%;">Thomas algorithm for tridiagonal linear algebra equations</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs038.html#___sec37" style="font-size: 80%;">Thomas algorithm, forward substitution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs039.html#___sec38" style="font-size: 80%;">Thomas algorithm, backward substitution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs040.html#___sec39" style="font-size: 80%;">Thomas algorithm and counting of operations (floating point and memory)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs041.html#___sec40" style="font-size: 80%;">"Example: Transpose of a matrix":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs042.html#___sec41" style="font-size: 80%;">"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs043.html#___sec42" style="font-size: 80%;">How do we define speedup? Simplest form</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs044.html#___sec43" style="font-size: 80%;">How do we define speedup? Correct baseline</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs045.html#___sec44" style="font-size: 80%;">Parallel  speedup</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs046.html#___sec45" style="font-size: 80%;">Speedup and memory</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs047.html#___sec46" style="font-size: 80%;">Upper bounds on speedup</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs048.html#___sec47" style="font-size: 80%;">Amdahl's law</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs049.html#___sec48" style="font-size: 80%;">How much is parallelizable</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs050.html#___sec49" style="font-size: 80%;">Today's situation of parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs051.html#___sec50" style="font-size: 80%;">Overhead present in parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs052.html#___sec51" style="font-size: 80%;">Parallelizing a sequential algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs053.html#___sec52" style="font-size: 80%;">Strategies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs054.html#___sec53" style="font-size: 80%;">How do I run MPI on a PC/Laptop?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs055.html#___sec54" style="font-size: 80%;">Can I do it on my own PC/laptop? OpenMP installation</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs056.html#___sec55" style="font-size: 80%;">Installing MPI</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs057.html#___sec56" style="font-size: 80%;">Installing MPI and using Qt</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs058.html#___sec57" style="font-size: 80%;">Using "Smaug":"http://comp-phys.net/cluster-info/using-smaug/", the CompPhys computing cluster</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs059.html#___sec58" style="font-size: 80%;">What is Message Passing Interface (MPI)?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs060.html#___sec59" style="font-size: 80%;">Going Parallel with MPI</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs061.html#___sec60" style="font-size: 80%;">MPI is a library</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs062.html#___sec61" style="font-size: 80%;">Bindings to MPI routines</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs063.html#___sec62" style="font-size: 80%;">Communicator</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs064.html#___sec63" style="font-size: 80%;">Some of the most  important MPI functions</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs065.html#___sec64" style="font-size: 80%;">"The first MPI C/C++ program":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program2.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs066.html#___sec65" style="font-size: 80%;">The Fortran program</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs067.html#___sec66" style="font-size: 80%;">Note 1</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs068.html#___sec67" style="font-size: 80%;">"Ordered output with MPIBarrier":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program3.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs069.html#___sec68" style="font-size: 80%;">Note 2</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs070.html#___sec69" style="font-size: 80%;">"Ordered output":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program4.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs071.html#___sec70" style="font-size: 80%;">Note 3</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs072.html#___sec71" style="font-size: 80%;">Note 4</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs073.html#___sec72" style="font-size: 80%;">"Numerical integration in parallel":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program6.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs074.html#___sec73" style="font-size: 80%;">Dissection of trapezoidal rule with \( MPI\_reduce \)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs075.html#___sec74" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs076.html#___sec75" style="font-size: 80%;">Integrating with <b>MPI</b></a></li>
     <!-- navigation toc: --> <li><a href="._para-bs077.html#___sec76" style="font-size: 80%;">How do I use \( MPI\_reduce \)?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs078.html#___sec77" style="font-size: 80%;">More on \( MPI\_Reduce \)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs079.html#___sec78" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs080.html#___sec79" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs081.html#___sec80" style="font-size: 80%;">"The quantum dot program for two electrons":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/ParallelizationMPI/MPIvmcqdot.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs082.html#___sec81" style="font-size: 80%;">What is OpenMP</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs083.html#___sec82" style="font-size: 80%;">Getting started, things to remember</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs084.html#___sec83" style="font-size: 80%;">General code structure</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs085.html#___sec84" style="font-size: 80%;">Parallel region</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs086.html#___sec85" style="font-size: 80%;">Hello world, not again, please!</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs087.html#___sec86" style="font-size: 80%;">Important OpenMP library routines</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs088.html#___sec87" style="font-size: 80%;">Parallel for loop</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs089.html#___sec88" style="font-size: 80%;">Example code</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs090.html#___sec89" style="font-size: 80%;">More on Parallel for loop</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs091.html#___sec90" style="font-size: 80%;">Inner product</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs092.html#___sec91" style="font-size: 80%;">Different threads do different tasks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs093.html#___sec92" style="font-size: 80%;">Single execution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs094.html#___sec93" style="font-size: 80%;">Coordination and synchronization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs095.html#___sec94" style="font-size: 80%;">Data scope</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs096.html#___sec95" style="font-size: 80%;">Some remarks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs097.html#___sec96" style="font-size: 80%;">Parallelizing nested for-loops</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs098.html#___sec97" style="font-size: 80%;">Nested parallelism</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs099.html#___sec98" style="font-size: 80%;">Parallel tasks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs100.html#___sec99" style="font-size: 80%;">Common mistakes</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs101.html#___sec100" style="font-size: 80%;">Matrix-matrix multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs102.html#___sec101" style="font-size: 80%;">Matrix-matrix multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs103.html#___sec102" style="font-size: 80%;">Matrix-matrix multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs104.html#___sec103" style="font-size: 80%;">Matrix-matrix multiplication</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0010"></a>
<!-- !split -->

<h2 id="___sec9">Different parallel programming paradigms  </h2>
<div class="panel panel-default">
<div class="panel-body">
<p> <!-- subsequent paragraphs come in larger fonts, so start with a paragraph -->

<ul>
<li> <b>Task parallelism</b>:  the work of a global problem can be divided into a number of independent tasks, which rarely need to synchronize.  Monte Carlo simulations represent a typical situation. Integration is another. However this paradigm is of limited use.</li>
<li> <b>Data parallelism</b>:  use of multiple threads (e.g. one or more threads per processor) to dissect loops over arrays etc.  Communication and synchronization between processors are often hidden, thus easy to program. However, the user surrenders much control to a specialized compiler. Examples of data parallelism are compiler-based parallelization and OpenMP directives.</li> 
</ul>
</div>
</div>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._para-bs009.html">&laquo;</a></li>
  <li><a href="._para-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._para-bs002.html">3</a></li>
  <li><a href="._para-bs003.html">4</a></li>
  <li><a href="._para-bs004.html">5</a></li>
  <li><a href="._para-bs005.html">6</a></li>
  <li><a href="._para-bs006.html">7</a></li>
  <li><a href="._para-bs007.html">8</a></li>
  <li><a href="._para-bs008.html">9</a></li>
  <li><a href="._para-bs009.html">10</a></li>
  <li class="active"><a href="._para-bs010.html">11</a></li>
  <li><a href="._para-bs011.html">12</a></li>
  <li><a href="._para-bs012.html">13</a></li>
  <li><a href="._para-bs013.html">14</a></li>
  <li><a href="._para-bs014.html">15</a></li>
  <li><a href="._para-bs015.html">16</a></li>
  <li><a href="._para-bs016.html">17</a></li>
  <li><a href="._para-bs017.html">18</a></li>
  <li><a href="._para-bs018.html">19</a></li>
  <li><a href="._para-bs019.html">20</a></li>
  <li><a href="">...</a></li>
  <li><a href="._para-bs104.html">105</a></li>
  <li><a href="._para-bs011.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

